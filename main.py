# main.py (ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥æµ‹è¯•)
import json
import time
from data_processor import DataProcessor
from question_generator import QuestionGenerator, Question
from config import config

def test_qwen_api():
    """æµ‹è¯•åƒé—®APIè¿æ¥"""
    from openai import OpenAI
    
    print("æµ‹è¯•åƒé—®APIè¿æ¥...")
    
    client = OpenAI(
        api_key=config.DASHSCOPE_API_KEY,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )
    
    try:
        response = client.chat.completions.create(
            model="qwen3-max",
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±"}
            ],
            max_tokens=50
        )
        print(f"âœ… APIè¿æ¥æˆåŠŸï¼")
        print(f"å“åº”: {response.choices[0].message.content[:100]}...")
        return True
    except Exception as e:
        print(f"âŒ APIè¿æ¥å¤±è´¥: {e}")
        return False

def run_single_experiment():
    """è¿è¡Œå•æ¬¡å®éªŒ"""
    print("=" * 60)
    print("å®éªŒ3.2ï¼šé€‰é¡¹è´¨é‡ä¸åˆ†å¸ƒç‰¹å¾åˆ†æï¼ˆå•æ¬¡æµ‹è¯•ï¼‰")
    print("=" * 60)
    
    # 0. æµ‹è¯•APIè¿æ¥
    if not test_qwen_api():
        print("è¯·æ£€æŸ¥DASHSCOPE_API_KEYé…ç½®")
        return
    
    # 1. æ•°æ®å‡†å¤‡
    print("\n1. å‡†å¤‡æ•°æ®...")
    processor = DataProcessor()
    sample_text = processor.get_sample_text()
    chunks = processor.split_into_chunks(sample_text, config.NUM_QUESTIONS)
    
    print(f"æ–‡æœ¬é•¿åº¦: {len(sample_text)} å­—ç¬¦")
    print(f"åˆ†å‰²æˆ {len(chunks)} ä¸ªç‰‡æ®µ")
    print(f"ç¬¬ä¸€ä¸ªç‰‡æ®µé¢„è§ˆ:\n{chunks[0][:200]}...\n")
    
    # 2. åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = QuestionGenerator()
    
    # 3. ç”ŸæˆBaselineé¢˜ç›®
    print("\n" + "-" * 40)
    print("Baselineæ–¹æ³•")
    print("-" * 40)
    baseline_question = generator.generate_baseline_question(chunks[0])
    
    # ä¸ºBaselineè®¡ç®—ç›¸ä¼¼åº¦
    baseline_similarities = generator.calculate_baseline_similarities(baseline_question)
    
    # 4. ç”ŸæˆRAGé¢˜ç›®
    print("\n" + "-" * 40)
    print("RAGæ–¹æ³•")
    print("-" * 40)
    rag_question = generator.generate_rag_question(chunks[0])
    
    # 5. æ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 60)
    print("å®éªŒç»“æœå¯¹æ¯”")
    print("=" * 60)
    
    # Baselineç»“æœ
    print("\nğŸ“Š Baselineæ–¹æ³•ç»“æœ:")
    print(f"é—®é¢˜: {baseline_question.text}")
    print("\né€‰é¡¹:")
    for i, option in enumerate(baseline_question.options):
        correct_mark = "âœ“" if i == baseline_question.correct_idx else " "
        similarity = baseline_similarities[i] if baseline_similarities else 0
        print(f"  {correct_mark} {i+1}. {option} (ç›¸ä¼¼åº¦: {similarity:.3f})")
    
    print(f"\nâ±ï¸ æ—¶é—´æˆæœ¬:")
    print(f"  ç”Ÿæˆæ—¶é—´: {baseline_question.generation_time:.3f}s")
    print(f"  Embeddingæ—¶é—´: {baseline_question.embedding_time:.3f}s")
    print(f"  æ€»æ—¶é—´: {baseline_question.generation_time + baseline_question.embedding_time:.3f}s")
    
    # RAGç»“æœ - æ˜¾ç¤ºåŸå§‹8ä¸ªé€‰é¡¹
    print("\nğŸ“Š RAGæ–¹æ³•ç»“æœ:")
    print(f"é—®é¢˜: {rag_question.text}")
    print("\nåŸå§‹8ä¸ªé€‰é¡¹åŠå…¶ç›¸ä¼¼åº¦:")
    for i, option in enumerate(rag_question.original_options):
        correct_mark = "âœ“" if i == rag_question.original_correct_idx else " "
        similarity = rag_question.original_similarities[i] if rag_question.original_similarities else 0
        print(f"  {correct_mark} {i+1}. {option} (ç›¸ä¼¼åº¦: {similarity:.3f})")

    # æ˜¾ç¤ºæ’åºå’Œè¿‡æ»¤è¿‡ç¨‹
    print("\nğŸ” é€‰é¡¹è¿‡æ»¤è¿‡ç¨‹:")
    # è·å–å¹²æ‰°é¡¹çš„ç´¢å¼•å’Œç›¸ä¼¼åº¦
    distractor_indices = [i for i in range(len(rag_question.original_options)) 
                        if i != rag_question.original_correct_idx]
    distractor_similarities = [rag_question.original_similarities[i] for i in distractor_indices]

    # æŒ‰ç›¸ä¼¼åº¦å¯¹å¹²æ‰°é¡¹è¿›è¡Œæ’åº
    sorted_distractors = sorted(
        zip(distractor_indices, distractor_similarities),
        key=lambda x: x[1]
    )

    print("  å¹²æ‰°é¡¹æŒ‰ç›¸ä¼¼åº¦æ’åº:")
    for rank, (original_idx, similarity) in enumerate(sorted_distractors):
        option_text = rag_question.original_options[original_idx]
        
        # åˆ¤æ–­æ˜¯å¦è¢«åˆ é™¤
        if len(sorted_distractors) >= 5:
            if rank < 2:  # ä¸¤ä¸ªæœ€ä¸ç›¸ä¼¼çš„
                tag = "âŒ åˆ é™¤ (æœ€ä¸ç›¸ä¼¼)"
            elif rank >= len(sorted_distractors) - 2:  # ä¸¤ä¸ªæœ€ç›¸ä¼¼çš„
                tag = "âŒ åˆ é™¤ (æœ€ç›¸ä¼¼)"
            else:
                tag = "âœ… ä¿ç•™"
        else:
            # å¦‚æœå¹²æ‰°é¡¹å°‘äº5ä¸ªï¼Œä½¿ç”¨ç®€åŒ–çš„è¿‡æ»¤é€»è¾‘
            keep_count = max(0, len(sorted_distractors) - 4)
            remove_each_side = (len(sorted_distractors) - keep_count) // 2
            if rank < remove_each_side or rank >= len(sorted_distractors) - remove_each_side:
                tag = "âŒ åˆ é™¤"
            else:
                tag = "âœ… ä¿ç•™"
        
        print(f"    ç›¸ä¼¼åº¦ {similarity:.3f}: {option_text} - {tag}")

    # æ˜¾ç¤ºå“ªäº›å¹²æ‰°é¡¹è¢«é€‰ä¸­ï¼ˆä»æœ€ç»ˆé€‰é¡¹ä¸­è·å–ï¼‰
    print(f"\nğŸ“¦ æœ€ç»ˆè¿‡æ»¤åçš„4ä¸ªé€‰é¡¹:")
    for i, option in enumerate(rag_question.options):
        correct_mark = "âœ“" if i == rag_question.correct_idx else " "
        similarity = rag_question.similarities[i] if rag_question.similarities else 0
        print(f"  {correct_mark} {i+1}. {option} (ç›¸ä¼¼åº¦: {similarity:.3f})")

    print(f"\nâ±ï¸ æ—¶é—´æˆæœ¬:")
    print(f"  ç”Ÿæˆæ—¶é—´: {rag_question.generation_time:.3f}s")
    print(f"  Embeddingæ—¶é—´: {rag_question.embedding_time:.3f}s")
    print(f"  è¿‡æ»¤æ—¶é—´: {rag_question.filtering_time:.3f}s")
    print(f"  æ€»æ—¶é—´: {rag_question.generation_time + rag_question.embedding_time + rag_question.filtering_time:.3f}s")
    
    # 6. ç»Ÿè®¡åˆ†æ
    print("\n" + "=" * 60)
    print("ç»Ÿè®¡åˆ†æ")
    print("=" * 60)
    
    # æå–å¹²æ‰°é¡¹ç›¸ä¼¼åº¦ï¼ˆæ’é™¤æ­£ç¡®é€‰é¡¹ï¼‰
    baseline_distractor_sims = []
    if baseline_similarities:
        baseline_distractor_sims = [sim for i, sim in enumerate(baseline_similarities) 
                                   if i != baseline_question.correct_idx]
    
    rag_distractor_sims = []
    if rag_question.similarities:
        rag_distractor_sims = [sim for i, sim in enumerate(rag_question.similarities) 
                              if i != rag_question.correct_idx]
    
    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    import numpy as np
    
    if baseline_distractor_sims:
        print(f"\nBaselineå¹²æ‰°é¡¹ç›¸ä¼¼åº¦ç»Ÿè®¡:")
        print(f"  å¹³å‡å€¼: {np.mean(baseline_distractor_sims):.3f}")
        print(f"  æ ‡å‡†å·®: {np.std(baseline_distractor_sims):.3f}")
        print(f"  èŒƒå›´: [{min(baseline_distractor_sims):.3f}, {max(baseline_distractor_sims):.3f}]")
    
    if rag_distractor_sims:
        print(f"\nRAGå¹²æ‰°é¡¹ç›¸ä¼¼åº¦ç»Ÿè®¡:")
        print(f"  å¹³å‡å€¼: {np.mean(rag_distractor_sims):.3f}")
        print(f"  æ ‡å‡†å·®: {np.std(rag_distractor_sims):.3f}")
        print(f"  èŒƒå›´: [{min(rag_distractor_sims):.3f}, {max(rag_distractor_sims):.3f}]")
    
    # é•¿åº¦åå·®åˆ†æ
    baseline_lengths = [len(opt) for opt in baseline_question.options]
    rag_lengths = [len(opt) for opt in rag_question.options]
    
    baseline_correct_length = baseline_lengths[baseline_question.correct_idx]
    rag_correct_length = rag_lengths[rag_question.correct_idx]
    
    print(f"\né•¿åº¦åå·®åˆ†æ:")
    print(f"  Baselineæ­£ç¡®é€‰é¡¹é•¿åº¦: {baseline_correct_length}")
    print(f"  Baselineé€‰é¡¹é•¿åº¦èŒƒå›´: [{min(baseline_lengths)}, {max(baseline_lengths)}]")
    print(f"  æ­£ç¡®é€‰é¡¹æ˜¯å¦æœ€é•¿æˆ–æœ€çŸ­: {baseline_correct_length == max(baseline_lengths) or baseline_correct_length == min(baseline_lengths)}")
    
    print(f"\n  RAGæ­£ç¡®é€‰é¡¹é•¿åº¦: {rag_correct_length}")
    print(f"  RAGé€‰é¡¹é•¿åº¦èŒƒå›´: [{min(rag_lengths)}, {max(rag_lengths)}]")
    print(f"  æ­£ç¡®é€‰é¡¹æ˜¯å¦æœ€é•¿æˆ–æœ€çŸ­: {rag_correct_length == max(rag_lengths) or rag_correct_length == min(rag_lengths)}")
    
    # 7. ä¿å­˜ç»“æœ
    print("\n" + "=" * 60)
    print("ä¿å­˜ç»“æœ")
    print("=" * 60)
    
    results = {
        "experiment_info": {
            "experiment_name": "3.2 é€‰é¡¹è´¨é‡ä¸åˆ†å¸ƒç‰¹å¾åˆ†æï¼ˆå•æ¬¡æµ‹è¯•ï¼‰",
            "date": time.strftime("%Y-%m-%d %H:%M:%S"),
            "model": config.GENERATION_MODEL,
            "embedding_model": config.EMBEDDING_MODEL,
            "embedding_dimensions": config.EMBEDDING_DIMENSIONS,
            "num_questions": config.NUM_QUESTIONS
        },
        "baseline": baseline_question.to_dict(),
        "rag": rag_question.to_dict(),
        "statistics": {
            "baseline": {
                "distractor_similarity_mean": float(np.mean(baseline_distractor_sims)) if baseline_distractor_sims else 0,
                "distractor_similarity_std": float(np.std(baseline_distractor_sims)) if baseline_distractor_sims else 0,
                "length_bias": baseline_correct_length == max(baseline_lengths) or baseline_correct_length == min(baseline_lengths)
            },
            "rag": {
                "distractor_similarity_mean": float(np.mean(rag_distractor_sims)) if rag_distractor_sims else 0,
                "distractor_similarity_std": float(np.std(rag_distractor_sims)) if rag_distractor_sims else 0,
                "length_bias": rag_correct_length == max(rag_lengths) or rag_correct_length == min(rag_lengths)
            }
        }
    }
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open("single_experiment_result.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"ç»“æœå·²ä¿å­˜åˆ°: single_experiment_result.json")
    
    # 8. æ€»ç»“
    print("\n" + "=" * 60)
    print("å®éªŒæ€»ç»“")
    print("=" * 60)
    
    print(f"\nâœ… å®éªŒå®Œæˆï¼")
    
    if baseline_question.generation_time + baseline_question.embedding_time > 0:
        time_ratio = (rag_question.generation_time + rag_question.embedding_time + rag_question.filtering_time) / \
                     (baseline_question.generation_time + baseline_question.embedding_time)
        print(f"æ€»è€—æ—¶:")
        print(f"  Baseline: {baseline_question.generation_time + baseline_question.embedding_time:.2f}s")
        print(f"  RAG: {rag_question.generation_time + rag_question.embedding_time + rag_question.filtering_time:.2f}s")
        print(f"  RAGæ¯”Baselineæ…¢ {time_ratio:.1f} å€")
    else:
        print("æ— æ³•è®¡ç®—æ—¶é—´æ¯”ç‡")
    
    return results

if __name__ == "__main__":
    # æ£€æŸ¥APIå¯†é’¥
    from config import config
    
    if not config.DASHSCOPE_API_KEY:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        print("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®DASHSCOPE_API_KEY=your_api_key")
        exit(1)
    
    print("âœ… ç¯å¢ƒæ£€æŸ¥å®Œæˆ")
    print(f"ğŸ“Š å½“å‰åµŒå…¥ç»´åº¦: {config.EMBEDDING_DIMENSIONS}")
    print(f"ğŸ“Š åµŒå…¥æ¨¡å‹: {config.EMBEDDING_MODEL}")
    run_single_experiment()